<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="- [摘 要](#摘-要) - [Abstract](#abstract) - [1 绪论](#1-绪论)   - [1.1 课题背景及目的](#11-课题背景及目的)   - [1.2 国内外研究状况](#12-国内外研究状况)   - [1.3 课题研究内容](#13-课题研究内容) - [2 图像对齐](#2-图像对齐)   - [2.1 选定参考帧](#21-选定参考帧)   - [2.">
<meta name="keywords" content="HDR+,图像">
<meta property="og:type" content="article">
<meta property="og:title" content="HDR+滤镜算法的实现">
<meta property="og:url" content="http://yoursite.com/2019/02/12/HDR-滤镜算法的实现/index.html">
<meta property="og:site_name" content="jiangbaige&#39;s blogs">
<meta property="og:description" content="- [摘 要](#摘-要) - [Abstract](#abstract) - [1 绪论](#1-绪论)   - [1.1 课题背景及目的](#11-课题背景及目的)   - [1.2 国内外研究状况](#12-国内外研究状况)   - [1.3 课题研究内容](#13-课题研究内容) - [2 图像对齐](#2-图像对齐)   - [2.1 选定参考帧](#21-选定参考帧)   - [2.">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-02-13T07:09:53.035Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HDR+滤镜算法的实现">
<meta name="twitter:description" content="- [摘 要](#摘-要) - [Abstract](#abstract) - [1 绪论](#1-绪论)   - [1.1 课题背景及目的](#11-课题背景及目的)   - [1.2 国内外研究状况](#12-国内外研究状况)   - [1.3 课题研究内容](#13-课题研究内容) - [2 图像对齐](#2-图像对齐)   - [2.1 选定参考帧](#21-选定参考帧)   - [2.">






  <link rel="canonical" href="http://yoursite.com/2019/02/12/HDR-滤镜算法的实现/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>HDR+滤镜算法的实现 | jiangbaige's blogs</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">jiangbaige's blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">learning notes</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/12/HDR-滤镜算法的实现/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="baige jiang">
      <meta itemprop="description" content="Record learning notes at any time">
      <meta itemprop="image" content="/images/background.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jiangbaige's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">HDR+滤镜算法的实现

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-02-12 22:04:55" itemprop="dateCreated datePublished" datetime="2019-02-12T22:04:55+08:00">2019-02-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-02-13 15:09:53" itemprop="dateModified" datetime="2019-02-13T15:09:53+08:00">2019-02-13</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/毕业设计/" itemprop="url" rel="index"><span itemprop="name">毕业设计</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <!-- TOC START min:1 max:4 link:true update:true -->
<pre><code>- [摘 要](#摘-要)
- [Abstract](#abstract)
- [1 绪论](#1-绪论)
  - [1.1 课题背景及目的](#11-课题背景及目的)
  - [1.2 国内外研究状况](#12-国内外研究状况)
  - [1.3 课题研究内容](#13-课题研究内容)
- [2 图像对齐](#2-图像对齐)
  - [2.1 选定参考帧](#21-选定参考帧)
  - [2.2 处理原始图像](#22-处理原始图像)
  - [2.3 分层对齐](#23-分层对齐)
  - [2.4 快速子像素 L2 对齐](#24-快速子像素-l2-对齐)
- [3 图像合并](#3-图像合并)
  - [3.1 噪点模型和平铺近似](#31-噪点模型和平铺近似)
  - [3.2 空间去噪](#32-空间去噪)
  - [3.3 合并 Bayer 原始](#33-合并-bayer-原始)
  - [3.4 工件](#34-工件)
- [4 精加工](#4-精加工)
  - [4.1 黑电平矫正](#41-黑电平矫正)
  - [4.2 透镜阴影校正](#42-透镜阴影校正)
  - [4.3 白平衡](#43-白平衡)
  - [4.4 去马赛克](#44-去马赛克)
  - [4.5 色度去噪](#45-色度去噪)
  - [4.6 色彩校正](#46-色彩校正)
  - [4.7 动态范围压缩](#47-动态范围压缩)
  - [4.8 图像去雾](#48-图像去雾)
  - [4.9 全局色调调节](#49-全局色调调节)
  - [4.10 色差校正](#410-色差校正)
  - [4.11 使用反锐化掩模进行锐化](#411-使用反锐化掩模进行锐化)
  - [4.12 色调特定](#412-色调特定)
  - [4.13 抖动](#413-抖动)
- [5 滤镜算法实现与分析](#5-滤镜算法实现与分析)
  - [5.1 实验环境配置](#51-实验环境配置)
  - [5.2 代码实现](#52-代码实现)
  - [5.3 实验分析](#53-实验分析)
  - [5.3.1 性能分析](#531-性能分析)
  - [5.3.2 问题与展望](#532-问题与展望)
- [6 结论](#6-结论)
- [参考文献](#参考文献)
- [致 谢](#致-谢)
</code></pre><!-- TOC END -->
<p><center>摘 要</center><br>通常来说，手机相机的光圈很小，这使得拍摄者使用手机相机拍摄时曝光度很难提高，从而导致在低光下图像频繁出现噪点。再者手机相机的传感器像素也很小，使得每个像素存储的电子数量很少，导致手机拍摄出来的照片动态范围相对有限。本算法描述了一个计算图像处理流水线，包括对齐和合并，精加工等处理一连串连拍帧以减少图像噪点并增加动态范围的系统。本算法详细功能描述如下。首先，输入的图像选择的是拜耳原始帧，而不是移动平台上常见的硬件图像信号处理器（ISP）生成的去马赛克 RGB（或 YUV）帧。这使得输入的图像拥有更多的像素位数，并且可以帮助算法规避 ISP 处理过程中的不需要的色调映射和空间去噪。其次，算法使用了基于 FFT 的新型对齐算法和混合 2D / 3D维纳滤波器来消除和合并连拍中的帧。第三，算法的实现建立在能够调用 Android 的Camera2 API 的基础之上，该 API 提供了可以对原始图像访问的机会，并且算法要求使用 Halide 域专用语言（DSL）编写。<br><strong>关键词</strong>：合并;对齐;图像计算;高动态范围</p>
<p><strong><center>Abstract</center></strong><br>Generally, cell phone cameras have small apertures, which limits the number of photons they can gather, leading to noisy images in low light. They also have small sensor pixels, which limits the number of electrons each pixel can store, leading to limited dynamic range. We describe a computational photography pipeline that aligns, and merges a burst of frames to reduce noise and increase dynamic range. Our system has several key features that help make it robust and efficient. First, we begin from Bayer raw frames rather than the demosaicked RGB (or YUV) frames produced by hardware Image Signal Processors (ISPs) common on mobile platforms. This gives us more bits per pixel and allows us to circumvent the ISP’s unwanted tone mapping and spatial denoising. Second, we use a novel FFT-based alignment algorithm and a hybrid 2D/3D Wiener filter to denoise and merge the frames in a burst. Third, our implementation is built atop Android’s Camera2 API, which provides per-frame camera control and access to raw imagery, and is written in the Halide domain-specific language (DSL).<br><strong>Keywords</strong>: aligning; merging; computational photography; high dynamic</p>
<p>1 绪论<br>1.1 课题背景及目的<br>一般来说，改善图片质量的主要技术困难是缺少光线。在暗室或晚间摄影时，场景很可能出现缺少光线的情况。标准的解决方案是应用放大噪声模拟或数字增益，或延长曝光时间，以解决相机抖动或拍摄物体移动导致的运动模糊问题。但是，令人惊讶的是高动态范围应用在白天的拍摄时也会出现因缺乏光线而使图片质量受到影响的状况。 尤其是，当你为了避免高光溢出而选择减少曝光时间时，则很可能会出现在阴影区域收集不到充足的光线的情况。如果您选择使用本地色调映射，是可以使这些阴影区域更明亮，但这又会引起新的问题——图像噪点放大。因此，本算法的目的就是为了解决这种缺乏光线的低光环境下图像拍摄的质量问题。特别是如果选择不使用物理办法解决，包括不使用大光圈镜头，光学防抖，包围曝光或闪光等方法。只通过算法处理使得在光线不足的情况下，拍摄出来的图片依然十分自然，而又不会产生高光溢出的情况。同时，该算法又要保证操作起来非常简单，使得对该算法完全不懂的小白拍摄人士，也能十分轻松的使用。<br>1.2 国内外研究状况<br>Google 公司针对 Pixel 手机提出的 HDR+方法，在增强图片质量方面取得了很好的效果，HDR+算法的原理是在很短的时间内拍一系列曝光时间相同的照片，然后再合成。HDR 算法运行需要大量计算，因此在拍摄选择 HDR 模式之后，会需要一定时间的处理才能完成 HDR 运算。为了解决这一问题，Pixel2 使用专用图像处理协处理器，即 ImageProcessing Unit，这是 Google 推出的第二颗芯片。IPU 的发布一方面彰显了在摩尔定律遇到瓶颈的今天，异构计算正在渐渐成为主流；另一方面，互联网厂商不惜花大代价制造专用芯片。IPU 支持加速的编程语言包括 Halide 和 TensorFlow，其中Halide 是为了机器视觉硬件执行效率进行过仔细优化的编程语言，可以轻松写出各种并行执行结构，在高性能机器视觉领域得到了大量应用。在 IPU 上运行 HDR+只需要1/5 的时间，1/10 的功耗，这大幅度提升了用户体验。这使得未来 HDR+算法推广到各大移动手机平台提供了基础。<br>鉴于算法要应用于手机这一限制，Google 公司选择足够低的曝光以避免场景出现高光溢出即故意向下暴露来捕捉更多的动态范围。无论拍摄场景内容如何，Google 坚持选择比典型的曝光时间更短的时间来减轻相机抖动模糊[1]。尽管使用较低的曝光可能会恶化噪声，但算法通过后续捕获和合并多个帧来抵消这种影响。<br>由于这种限制而产生的第二个设计决定是，Google 选择连拍图像中的一张作为“参考”帧，然后将这些帧中的那些补丁与确信已经成像的其他“替代”帧对齐并合并，对齐合并的部分为与此帧中场景相同的部分。通过对齐和合并多个帧，算法生成的中间图像比开始输入的帧具有更高的比特深度，更高的动态范围和更低的噪声。这可以让算法仅仅通过丢弃低位来产生高质量（尽管曝光不足）的照片。然而，Google公司的目标之一就是制作出自然的照片，即使场景包含强烈的对比。因此，处理结果反而会增加阴影，保留局部对比度，同时明智地牺牲全球对比度。它的效果与印刷摄影中传统的“闪避和刻录”方法产生的效果类似[2]。Google 公司使用暴露融合的变体，因为它计算效率高，能够生成自然的图像。当然，其他算法也是可能可行的。<br>一般来说，为了收集更多光线，所使用的方法包括大光圈镜头，光学防抖，包围曝光或闪光等。但是，每种方法都会增加设备成本。首先，如果相机本身是手机的话，相机本身大小体积都不能过大，甚至应该微乎其微，让相机光圈变大太多几乎是不可能的。与此同时，设备还会受到手机电源的限制，因此使用双摄像头或者多摄像头的手机耗电量会大大增加[3]。如果选择使用光学防抖来增加曝光时间，同时将相机抖动模糊变至最低，是会在一定程度上提高拍摄效果，但是无法控制拍摄者自身移动引起的模糊。如果使用曝光包围和图像融合，则会因为拍摄的时间不同而很难实现完美融合。并且由于在不同时间拍摄的图像对齐困难，这种错误的融合很容易出现极端情况–重影。若果选择在相邻扫描线之间将传感器的曝光时间交替进行，则可以稍微改善图片的重影问题，但这种行为会牺牲掉图片的很多细节并给后续精确去马赛克过程增加困难。而使用相机的闪光灯则是最不可取的选择。它增加了光线，但是会很大程度上改变场景，并且在很多公共场合是禁止使用闪光灯的[4]。<br>1.3 课题研究内容<br>本毕业设计主要实现了一种高动态范围增强滤镜算法系统，其通过处理一系列捕捉的图像并将它们与动态范围压缩相结合来解决上述描述的光线不足问题。在构建该算法时，主要遵循以下设计原则：<br>•自动。摄影师可以在不知道拍摄或图像处理策略的情况下拍摄出好的照片。<br>•自然。拍摄的照片必须忠实于场景的外观。在 HDR 的情况下，要限制局部色调映射的量。在黑暗的场景中，我们不能使处理出来的图像过度高亮，以至于它会过度改变图像的亮度从而显示过度的噪点。<br>•保守。应该可以将其用作默认的拍照模式。这意味着拍摄的照片不得含有伪影，并且图像质量必须始终保持高于或者与持平于传统照片的质量。而且，在极端情况下，它必须逐渐退化为传统照片。<br>为了执行恒定的曝光协议，应在拍摄时选择足够低的曝光量以避免给定场景的裁剪（模糊的光线）。这样做可以捕捉更多的动态范围。无论场景的内容如何，相机抖动模糊的选择都比拍摄时的典型曝光时间短[1]。虽然使用较低的曝光量似乎会降低噪点，但稍后算法会通过合并多个帧来抵消这种影响。<br>遵循规定而产生的设计决定就是选择一张连拍中的图像作为“参考”帧，然后对齐并合并到这个帧中来自其他“替代”帧的那些补丁。在合并过程中，对于每个替代帧仅选择一个图像补丁，从而降低计算复杂度。这种保守的合并可能会导致最终图像的某些部分显得比其他部分更嘈杂，但这部分通常不太明显。<br>通过对齐和合并多个帧，生成的中间图相比输入帧具有更高的比特位深度，更高的动态范围和更低的噪点。这可以通过丢弃较低位而产生高质量（尽管曝光不足）的照片。然而，最终的目标之一是即使场景包含强烈的对比也能制作出自然的照片。因此，图像处理中会添加阴影，保留局部对比度，同时明智地牺牲全局对比度。这个过程被称为 HDR 色调映射，并已得到很好的研究[5]。</p>
<p>2 图像对齐<br>在对齐算法中，连拍的一系列非参考帧应严密对应选中的参考帧。过往历史中，前人们已经对对齐问题进行了大量的研究，曾经提出的解决方法包括光流[2,6]，应用补丁或特征描述符来构造和“密集”稀疏对应的技术[7,8]，或者使用图像矫正和直接推理几何和咬合[9]。以上技术都会生成高质量的通信信息，但计算成本很高，前面描述的每项技术在通用桌面环境上每 Mpix 运行时间需要 1.7 到 107 分钟。<br>虽然以上提出了众多技术，但都不适应于当前应用场景，它们对速度，内存和电源有着手机相机无法支持的硬件要求。但是，HDR+滤镜算法只需构建一个简单的合并算法，满足在粗略的，小的对齐错误上功能强大的要求即可。就像视频压缩系统一样[10]，我们这个系统要求的合并算法应该考虑并同时平衡计算成本和通信质量。最终系统选择使用的对齐算法是类似于的频域加速度方法[11]。具体算法流程如下：<br>2.1 选定参考帧<br>参考帧的选择定为连拍子集中最锐利的那帧图像并只从连拍图像中的前三帧图像中选择，这样既可以解决对拜耳原始图像绿色部分梯度的考量同时解决由于拍摄者抖动或者运动引起的画面模糊。这遵循被称为幸运成像的一般策略[12]。<br>2.2 处理原始图像<br>在对齐方面，使用拜耳原始图像进行对齐是很困难的，因为其原始图像的构成与RGB 图像区别很大。特别是在原始图像的四个色彩平面中因缺乏采样使得对齐困难。这里采用的方法是通过估计连续图像偏移只能是 2 个像素的倍数来绕过这个问题。在这个限制下的位移更方便取代拜耳原始图像样品中的重合颜色。同时为了降低采样图像的大小，将其限定为 3 Mpix 灰度图像，该算法会先将 2×2 块拜耳 RGGB 样本图像进行平均。这样就会将混叠不匹配图像以及其他未对齐图像推迟到合并阶段解决。<br>2.3 分层对齐<br>为了将参考帧与非参考帧对齐，对齐算法将进行从粗到细、从下采样到灰色原始输入的四级高斯金字塔上的对齐。如图 2.1 所示，每个金字塔等级生成一个基于当前图块的对齐方式，使用较粗尺度的对齐作为初始猜测。每个参考图块的对齐目标都是最小化它与候选图像的候选图块相关距离度量的偏移量：</p>
<p> 𝐷𝑝<br>(𝑢, 𝑣) = ∑ ∑ |𝑇(𝑥, 𝑦) − 𝐼(𝑥 + 𝑢 + 𝑢0, 𝑦 + 𝑣 + 𝑣0)|<br>𝑛=1 𝑝<br>𝑥=0<br>𝑛=1<br>𝑦=0 (2.1)<br>（a）采样图像。 （b）对齐过程与结果。<br>图 2.1 参考帧与非参考帧的对齐方式示例<br>其中T是参考图像的切片，I是替换图像的较大搜索区域，p是对准的范数的功率，并且 n 是切片的大小，并且（𝑢0，𝑣0）是由金字塔较粗糙层面上的切片继承的初始对齐[13]。<br>公式(2.1)中的模型暗示了关于脉冲运动的几个假设。我们假设分段平移，当贴片靠近单个像素时是有限的，但对于较大的贴片这可能是一个限制性假设。这里，图像块之间的绝对误差应该最小化，而不是最大化归一化的互相关，亮度和对比度不断变化。但是，这不是一个缺点，因为相机曝光是固定的，并且在连续拍摄期间不能快速改变照明。<br>当粗对齐跨越对象或运动边界时，将粗对齐上采样到金字塔的下一级是具有挑战性的[13] 。特别地，当在表示上采样片的初始猜测周围的搜索区域中没有最佳位移时，诸如最近邻居和双线性内插的标准上采样方法可能失败。这里我们选择通过评估每个上采样对齐的多个假设来解决这个问题，选择参考帧和交替帧之间具有最小 L1 残差的对齐[13]。以三个最接近的粗尺度地图作为候选，最近的邻居地图加上每个维度中的下一个最近的地图。这种方法在精神上与 SimpleFlow 类似[14]，它也使用图像内容来通知上采样。<br>在这种方法中，许多启发式决策都是针对公式(2.1)中的提取，补丁大小，搜索半径和标准选择进行的。一个关键的决定是基于金字塔维度进行不同的对齐。具体而言，在粗尺度下，计算子像素对齐以最小化 L2 残差并使用大的搜索半径。亚像素对齐在粗尺度上是有价值的，因为它增加了初始化的准确性并允许积极的金字塔抽取[13]。在金字塔的最佳尺度上，算法将计算像素级对齐，最小化 L1 残差，并将其本身限制在一个小的搜索范围内。这里只需要像素级对齐，因为当前合并进程不能使用子像素对齐。<br>2.4 快速子像素 L2 对齐<br>在粗尺度下，由于使用较大的搜索半径，仅使用公式(2.1)就会非常昂贵。在这里，我们选择使用算法技术来解决这个问题，以更有效地计算𝐷2。类似于可以加速归一化互相关的方式[11]，公式(2.1)的 L2 版本可以使用盒滤波器和卷积来计算：<br>𝐷2 = ||𝑇||2<br>2 + 𝑏𝑜𝑥(𝐼°<br>𝐼, 𝑛)2 (ℱ<br>−1<br>{ℱ{𝐼}<br>∗<br>°<br>ℱ{𝑇}}) (2.2)<br>第一项是 T 的平方元素的总和，第二项是由尺寸为 n×n（与 T 的尺寸相同）的非归一化盒滤波器过滤的 I 的平方元素。第三项与 I 和 T 之间的互相关成正比，用快速傅里叶变换有效地计算[13]。<br>在计算𝐷2之后，识别最小化位移误差的整数位移（u，v）是方便的。为了生成运动的亚像素估计，将一个二元多项式拟合到（u，v）周围的 3×3 窗口，并找出多项式的最小值[13]。这改进了拟合两个可分离函数的标准方法[15]，通过避免假想的运动，它们独立受其各自的轴限制。在形式上，近似于：<br>𝐷2<br>(𝑢, 𝑣) ≈$ \frac{1}{2} $<br>[𝑢 𝑣]𝐴 [<br>𝑢<br>𝑣<br>] + 𝑏<br>𝑇<br>[<br>𝑢<br>𝑣<br>] + 𝑐 (2.3)<br>其中 A 是 2×2 正半定矩阵，b 是 2×1 向量，c 是标量。这里构造加权最小二乘问题，将多项式拟合到以（u，v）为中心的𝐷2的 3×3 补丁[13]。解决这个系统相当于将𝐷2的内积乘以一组六个 3x3 滤波器，这些滤波器是在补充中获得的。每一个对应于（ A， b， c）中的一个自由参数。该过程类似于多项式展开方法[16]。一旦二次参数恢复，其最小值通过完全平方来求解：<br>μ= −A<br>−1𝑏 (2.4)<br>矢量μ表示必须添加到整数移位（u，v）的子像素转换。<br>总的来说，对齐方法通过选定最好的参考帧，实现参考帧与非参考帧从粗到细一一对齐，很好的解决了图像模糊问题。尤其是最后使用的傅里叶快速变换算法很好的实现了对算法的加速，为后续工作做好了铺垫。<br>3 图像合并<br>连拍摄影的关键前提是可以通过结合多次观察场景来实现降噪。但是，为了在摄影应用中有用，设计的合并方法必须在对齐失败时很有用。虽然对齐对于帮助补偿相机和物体的运动非常重要，但不能选择单独依靠对齐，这可能会导致在遮挡，非刚性运动或照明变化等情况下对齐失败。<br>考虑到性能问题，这里使用的合并方法是基于对输入切片进行操作的成对频域时间滤波器，可以对未对齐的情况进行强有力的处理。将引用的每个图块都与从每个替换帧中获取的一个图块合并，并将其与对齐结果对应。通常情况下会选择使用来自拜耳原始输入颜色平面的 16×16 切片，但对于非常黑暗的场景，低频噪点可能令人反感，因此改用使用 32×32 切片代替。<br>该方法从频域视频去噪技术中获得灵感，这些技术可以在 3D 堆叠的匹配图像补丁上运行[17,18]。特别是，Kokaram [17]提出了 3D DFT 域经典 Wiener 滤波的一个变体，衰减较小的系数更可能是噪点。 V-BM3D[18]采用了类似的方法，将维纳滤波器和类似算子重新解释为“缩小”算子，该算子偏好变换域中自然图像统计特性的稀疏性。该系列的技术对解决未对齐很有效，因为对于给定的空间频率，任何不能归因于预期噪点水平的参考失配都将被抑制。<br>最近的傅里叶爆发累积方法使用的就是类似的原理[19]，但在整个爆发中结合频率内容更积极，以减少长时间曝光引起的运动模糊。在极端情况下，这种方法包括在连拍中获取每个空间频率的最大值。在合并中会保留参考帧的运动模糊作为摄影的有用特征，并且将曝光不足和幸运成像组合在一起使不必要的运动模糊变得不那么常见。虽然这种合并方法继承了频域去噪的好处，但它以几种方式偏离了以前的方法。首先，因为处理原始图像，所以有一个简单的模型来描述图像中的噪点。这可以帮助算法更可靠地区分对齐失败和噪点来提高鲁棒性[13]。其次，这种合并方法不是在时间维上应用 DFT 或其他正交变换，而是使用更简单的成对过滤器，将每个替代帧独立地合并到参考帧上。虽然这种方法为良好对齐的图像牺牲了一些降噪功能，但通过对齐失败来计算和降级会更方便。第三，由于该滤波器仅在时间维上运行，故选择在单独的后处理步骤中运行空间去噪，应用于 2D DFT[13]。第四，这种合并方法将滤镜独立应用于拜耳原始图像的颜色平面，然后将滤波后的结果重新解释为新的拜耳图像。这种方法虽然简单但却令人惊讶，但即使忽略拜耳欠采样，也观察不到什么退化。在下文中，将详细介绍这些要点并讨论可能导致极端情况的工件。<br>3.1 噪点模型和平铺近似<br>因为我们使用拜耳原始数据，所以噪点对于每个像素都是以简单的，与信号相关的形式独立存在的。特别是对于 x 的信号电平，噪点方差𝜎2可以表示为 Ax + B，接着是光子计数的泊松分布物理过程[20]。参数 A 和 B 仅取决于我们直接控制的镜头的模拟和数字增益设置。为了验证这种传感器噪点模型，我们凭经验测量了噪点如何随着不同的信号电平和增益设置而变化。<br>在应用滤波的变换域中，直接使用信号相关模型过滤噪点是不切实际的，因为DFT 需要完整的协方差矩阵来表示。虽然可以通过输入应用方差稳定变换来解决这个问题，但为了提高计算效率，通常选择将噪点估计为在给定图块内独立于信号[21]。对于每个图块，通过使用单个值（即图块中样本的均方根（RMS））评估噪点模型来计算方差。使用 RMS 可将信号估计值偏向较亮的图像内容。对于低对比度切片，这与使用平均值相似;高对比度切片将被更积极地过滤，就好像它们具有更高的平均信号电平。<br>强大的成对时间合并使合并方法在空间频率域上的图像切片上运行。对于一个给定的参考切片，算法会在该脉冲串上组装一组相应的切片，每帧一个，并且将它们各自的 2D DFT 计算为𝑇𝑧(ω），其中ω=(ωx,ωy)表示空间频率，z 是帧索引，并且在不失一般性的情况下，以 0 帧为参考。<br>该方法偏离其他基于频率的去噪方法的地方是选择在时间维度上对帧进行成对处理。为了建立直觉，合并时间维度的简单方法是计算每个频率系数的平均值。这种简单的平均滤波器可以被认为是表达对去噪参考帧的估计[13]：<br>_<br>𝑇0<br>(𝜔)<br>1<br>𝑁<br>∑ 𝑇𝑧(𝜔)<br>𝑁=1<br>𝑧=0<br>(3.1)<br>虽然这在对齐成功的情况下表现良好，但对于对齐失败并不稳健（如图 3.1）。由于 2D DFT 是线性的，因此该滤波器实际上等同于空间域中的时间平均值。</p>
<p>注：（a）连拍图片示例。 （b）有重影的无对齐结果。 （c）鬼影结果。 （d）对齐失败的结果。<br>图 3.1 移动场景示例<br>为了增加鲁棒性，改为构造类似于公式 3.2 的表达式，但是包含了一个滤波器，可以控制交替帧的贡献：<br>_<br>𝑇0<br>(𝜔) =<br>1<br>𝑁<br>∑ 𝑇𝑧(𝜔)<br>𝑁=1<br>𝑧=0 + 𝐴𝑧(𝜔)[𝑇0<br>(𝜔) − 𝑇𝑧(𝜔) ] (3.2)<br>对于给定的频率，𝐴𝑧控制将交替帧 z 合并到最终结果与返回参考帧的程度。这个和的主体可以被重写为(1-𝐴𝑧)·𝑇𝑧 + 𝐴𝑧·𝑇0以强调𝐴𝑧控制𝑇𝑧和𝑇0之间的线性插值。由于每个替代帧的贡献是基于每个频率进行调整的，所以对齐失败可能是部分的，因为一个空间频率的被拒绝图像内容不会破坏其他频率。<br>现在剩下的任务是定义𝐴𝑧为衰减与参考不匹配的频率系数。特别是，当𝑇𝑧与𝑇0的差异归因于噪点时，希望𝑇𝑧对合并结果作出贡献，并且当它与𝑇0不同时由于对齐不良或其他问题而导致𝑇𝑧的贡献被抑制。换句话说，𝐴𝑧是一个缩小操作符[13]。对𝐴𝑧的定义是经典 Wiener 滤波器的变体：<br>𝐴𝑧<br>(𝜔) =<br>|𝐷𝑧(𝜔)|<br>2<br>|𝐷𝑧<br>(𝜔)|<br>2+𝑐𝜎2<br> (3.3)<br>其中𝐷𝑧(ω)= 𝑇0(ω)- 𝑇𝑧 (ω)，噪点方差𝜎2是噪点模型，并且𝑐是解决𝐷𝑧构造中的噪点方差的缩放的常数，并且包括进一步的调整 因素（在我们的实施中，固定为 8）增加了噪点降低，但以一些鲁棒性为代价[13]。 对于 2D DFT 样本的数量，构造𝐷𝑧将使噪点方差缩放𝑛2倍，窗口函数的因子为1/42，其定义的因子为 2，作为两个切片的差异。 尝试了几种可选的缩小算子，如硬阈值和软阈值，并且发现这种滤波器可以在降噪强度与视觉伪影之间提供最佳平衡[22]。</p>
<p>成对时间算子会产生比完整 3D DFT 更高质量的图像，特别是在对齐失败的情况下。如图 3.2 所示，单个不良对齐的框架使整个 DFT 变换域非稀疏，导致收缩算子拒绝来自所有交替帧的贡献，而不是仅差对齐的贡献。相比之下，临时操作员独立评估每个替代帧的贡献，让对齐失败时更优雅地降级。同时时态滤波还具有计算更便宜并且需要更少内存的优点。在进行下一步之前，可以计算并丢弃每个替代帧的贡献。<br>3.2 空间去噪<br>因为上面的成对时间滤波器不执行任何空间滤波，所以选择将空间滤波应用为 2DDFT 域中的单独后处理步骤。从时间滤波结果开始，选择通过将空间频率系数应用与公式(3.3)相同形式的逐点收缩算子来执行空间滤波。为了保守，通过假设所有 N 帧完美平均来限制去噪的强度。因此，将噪点方差的估计更新为𝜎2/ N。与人类视觉系统的经典研究一致，发现可以比较低的空间频率内容更积极地过滤高空间频率内容，而不会引入明显的人为因素。因此，这里选择应用一个“噪点整形”函数σ〜= f（ω）σ来调整有效噪点电平作为ω的函数，从而增加其频率的大小。通过定义一个分段线性函数来表示这个函数，将其调整为最大化主观图像质量而不是 SNR。<br>3.3 合并 Bayer 原始<br>注意到目前为止，已经根据单通道图像展示了合并算法。但是，如上所述，输入和输出都包含 Bayer-Mosaicked 原始图像。该算法设计以尽可能最简单的方式处理原始图像：比如使用常见的局部平移对齐方式独立合并 Bayer 图像的每个平面，并且不使用比 Bayer 颜色平面中的像素级更精确的对齐方式。调整为更高的精度将需要对齐和合并的插值，这将显着增加计算成本。虽然这种方法是快速有效的，但它不如多帧去马赛克算法（例如[23]）复杂，旨在恢复丢失拜耳欠采样的高频内容。<br>由于拜耳色彩平面欠采样 4 倍，人们可能悲观地认为 75％的帧会被平均拒绝，从而影响去噪。虽然鲁棒滤波器确实会拒绝不符合噪点模型的锯齿图像内容，但这种拒绝只发生在每个 DFT bin 的基础上，并且混叠问题可能局限于 DFT bin 的子集。在图6 中可以观察到相同的行为，尽管对齐不良（如图 3.2），但我们的鲁棒时间滤波器能够在不引入任何可见重影的情况下显着降低噪点（如图 3.2）。</p>
<p>(a) 对齐成功的信号 （b）对齐成功的信号（c）（a）的 DFT 收缩率 （d）（b）的 DFT 收缩率（e）对（a）的成对过滤 （f）对（b）的成对过滤<br>注：对齐成功（左列）时，与参考（第 0 帧）的所有差异均归因于噪点。在良好对齐的情况下，DFT 域信号强烈集中在 DC 库中，逐点缩小算子可以抑制噪点。如（a）所示，参考帧处的滤波输出信号非常接近真实信号。当对齐不成功时（右列），即使存在单个异常值（第 5 帧），两个方法的行为也会不同。在 DFT 域（d）中，异常值将所有系数提高到噪点水平以上，即使信号非稀疏，这降低了收缩的有效性。相反，我们的成对时间滤波器（f）允许收缩对除了未对齐的帧之外的所有图像都有效。最终的结果是，我们强大的成对合并具有比 DFT 更多的去噪，产生更接近真实信号（b）的输出信号。对于 DFT，单个异常值足以使结果保守地降低到噪点参考信号。<br>图 3.2 对齐失败的时间过滤行为<br>重叠切片。该合并方法在每个空间维度上重叠一半的切片上进行操作。通过在重叠的切片之间平滑地混合，避免了在切片边界处的视觉上令人讨厌的不连续性。此外，必须将窗函数应用于切片，以避免在 DFT 域中操作时出现边缘伪影。对于 0≤x&lt;n，使用修正的升余弦窗口 1/2 - 1/2cos（2π（x + 1/2）/n），否则为 0。这与传统定义不同：首先，余弦变元的分母是 n，而不是 n-1。与传统窗口不同，当使用 n / 2 个重叠样本重复此功能时，所有图块的总贡献总和为每个位置一个。其次，窗口移动了一半以避免由修改后的分母导致的窗口中的零。窗口中的零点对应于对输出没有贡献的像素，这意味着可以使用更小的图块大小（与相关联的计算节省）来实现相同的结果。<br>3.4 工件<br>已经观察到由这个系统产生的几类工件。首先，该滤波器往往无法抑制强烈高对比度特征周围的噪点。这是高对比度特征在空间 DFT 域中具有非稀疏表示的结果，降低了空间去噪的有效性。<br>其次，因为缩放功能从未完全拒绝对齐不良的切片，所以有时会出现轻微的重影伪影。根据经验，这些重影伪影很微妙，并且很难与运动模糊区分开来。<br>总的来说，滤波器偶尔会产生通常与频域滤波器相关的振铃伪影。尽管通过开窗方式可大大缓解响铃，但在充满挑战的情况下，经典的吉布斯现象可以被看到，特别是在我们的精加工管线中进行磨刀和其他步骤放大后。在邻近的低对齐的剪辑高光区域中，最常见的是铃声，这些高光显示出高时空对比度。根据经验，响铃对大多数场景的视觉效果可以忽略不计。</p>
<p>4 精加工<br>对齐和合并捕获的拜耳原始帧会生成具有高比特深度和 SNR 的单个原始图像[13]。在实践中，输入是 10 位原始数据，并将其合并到 12 位以保留从合并获得的精度。这个图像现在必须经过校正，去马赛克和色调映射 - 这些操作通常由 ISP 来执行，但在我们的情况下，这是通过软件实现的，并且包括动态范围压缩的关键附加步骤。按应用顺序，这些操作是：<br>4.1 黑电平矫正<br>传感器电路本身会存在暗电流，导致在没有光线照射的时候，像素单位也有一定的输出电压，暗电流这个东西跟曝光时间和gain都有关系，不同的位置也是不一样的。因此在 gain 增大的时候，电路的增益增大，暗电流也会增强，因此很多 ISP 会选择在不同 gain 下减去不同黑电平的值。因为这里我们不使用 ISP，所有要自行加算法进行处理。<br>现在的主流传感器都是自行处理黑电平。在 ISP 部分减掉的其实不是黑电平，而是传感器统一做出来的 pedestal。传感器端不会将黑电平减完，因为传感器输出不能为负数，若将黑电平减完，就等于小于 0 的部分直接就丢掉了，这样做会改变噪点的分布。<br>这里使用的解决办法是减去所有像素的偏移量，以便不接收光的像素变为零。从传感器上的光学屏蔽像素获得这种偏移。<br>4.2 透镜阴影校正<br>透镜阴影分为两种亮度阴影和色彩偏差。透镜阴影产生的原因是镜头的通光量从中心到边角依次较少，导致图像看起来，中间亮度正常，四周偏暗。 一般矫正的方法是获取矫正系数，计算待矫正像素点所在网格四个顶点的校正系数 ，计算待矫正像素的校正值进行矫正 。<br>这里使用的方法是增亮图像的角部以补偿透镜渐晕，并校正由于光以斜角照射传感器而在空间上变化的颜色。这些正是使用 ISP 提供的低分辨率 RGGB 图像执行的。<br>4.3 白平衡<br>讨论白平衡，那就要从色温(CCT)谈起，色温顾名思义就是色彩的温度，但是这个色温和我们一般所认知的冷色、暖色不同，它指的是一个绝对黑体(物理学家想象出来的)从绝对零度(-273℃)开始持续加温所呈现出来的颜色，譬如在炼钢炉里给一块铁加热，就会从黑到暗红再到亮红最后到金黄，接着就融化了，因为铁的熔点是 1535℃，所以更高温度的颜色就看不到。但从焊接用的火可以看到蓝色的火焰，那是更高的温度所辐射出来的颜色。这些颜色的差异来自于不同波长光线的比例不同，色温低的情况下（红色）波长较长的光线比例较大，反之亦然。那么就造成白色在高色温的光线照射下显得较蓝，在低色温的光线下显得较黄。而人眼中的白色总是 R = G = B，那么白平衡所做的事情就是在不同色温条件下将图像做归一化，也就是将传感器响应的RGB 分别乘上一个系数，使得”白色成为白色”。总而言之，白平衡的目的就是让物体在不同光源条件下所呈现出来的颜色，恢复到物体的固有色。<br>算法里使用的方法是对四个（RGGB）通道进行线性缩放，以使场景中的灰度映射到图像中的灰色。这些比例因子由 ISP 提供。<br>4.4 去马赛克<br>色彩插值又称去马赛克，经过色彩插值之后原来的灰度图像就成为了一幅三通道的彩色图像。空间插值有非常多的方法，首先要把单通道的灰度图像转换为三通道的彩色图像。完成这一步之后我们就得到了最原始的彩色信息。一些应用中所需要的就是这幅图像的数据。<br>具体操作是将图像从 Bayer 原始图像转换为每像素 12 位的全分辨率线性 RGB 图像。这里使用 Gunturk 等人的技术组合。包括带有加权平均的边缘插入插值，基于恒定色调的插值和作为校正项的二阶梯度。<br>4.5 色度去噪<br>一般情况下，色度噪点的大小会是亮度噪点的数倍至数十倍，表现为原色的斑点。在暗部层次较为平整的部分会比较明显，而在明亮或白色被摄体占据大部分画面的图像中不是十分明显。虽然它的存在对图像效果的影响很大，但如果通过“减噪”功能对其进行强行处理的话，便有可能破坏被摄体的色彩。因此，需要根据图像的状态来判断选择适当的“减噪”程度。<br>这里，算法选择减少暗光暗影区域中的红色和绿色斑点。为此，使用一个近似的双边滤波器，使用 YUV 中的两遍应用的稀疏 3x3 抽头非线性内核来实现。<br>4.6 色彩校正<br>色彩校正也称为校色，它是一个摄影后期的专用技术术语，而“调色”是俗称，其概念比较含混且不是专业术语。“调色”一词更多被个人对色调的主观喜好或艺术色调的渲染中所使用，“调色”与“校色”的本质区别在于，调色不需要懂得校色必须知道的光学理论，调色的概念与美术的颜料调配相似，仅凭个人对颜色的喜好和感受即可很快实现，它可以是偏向某种色调的不真实的“艺术”渲染，而校色的要求要比调色严格的多，其目的是准确还原人眼感受的拍摄现场之色调。确切的说校色是严谨的工作且有较严格的标准规范，这里使用 ISP 提供的 3x3 矩阵将传感器 RGB 的图像转换为线性 sRGB。<br>4.7 动态范围压缩<br>一副图像可见区域亮度的最大值与最小值之比被称为图像亮度的动态范围。通过眼睛瞳孔的自动调节，从刺眼的阳光到微弱的星光，人眼能分辨的亮度范围可以达到100000000:1，就算在同一个固定场景内，人眼不需要适应性调节也能观察近 10000:1的亮度范围。然而，常规显示设备能显示的亮度动态范围仅仅是 100:1.<br>近年来高动态范围图像正在受到越来越广泛的注意。HDR 图像色彩空间广大，层次丰富，可以达到远比普通图像更逼近现实的光影效果，在影片后期处理，游戏特效，卫星气象，医疗等领域都有巨大的应用价值。而 HDR 领域一项重要的研究课题就是压缩 HDR 的动态范围，使之适应显示于低动态范围的普通显示设备。这样的研究称为色调映射或色阶重建。其目标是在将高动态范围的亮度和颜色压缩到普通显示器可以接受的范围的同时，尽可能保留原图的重要信息及视觉效果，并避免造成图像瑕疵。理想的情况是：一个又高动态范围的场景生成的高动态范围的计算机图像，通过色调映射后显示在低动态范围的显示器上，在同样观察条件下，与原来真实世界的场景给人的视觉感受是相同的。<br>4.8 图像去雾<br>图像去雾技术离不开一个简单的自然模型——大气散射模型。大气散射模型描述了，在雾霾和光照的共同作用下的成像机制。阳光在物体表面形成反射光，反射光在穿过雾霾的过程发生散射，只有部分能量能到达摄像头。与此同时，阳光也在悬浮颗粒表面散射形成大气光被摄像头接收。因此，摄像头中的成像可由两部分组成，透射的物体亮度和散射的大气光照。其中，媒介透射率顾名思义表示能顺利透过雾霾到达摄像头的比率。而透射率跟物体与摄像头距离成反比，离摄像头越远的物体受雾霾影响更大。当距离趋于无穷大时，透射率趋于零。综上所述，去雾的核心是如何更精确地估计媒介透射率。<br>本次算法是通过应用全局色调曲线来降低遮挡眩光的影响，该色调曲线将低像素值推到更低的位置，同时保留中间调和高光。具体来说，允许多达 0.1％的像素被钳位到零，但只能调整低于白色电平 7％的像素。<br>4.9 全局色调调节<br>一般为了得到更好的显示效果，亮度与 Gamma 校正通常是必不可少的。但是，如果对最后输出的图像存有异议，强烈建议首先返回到这一步中来寻找问题。根据经验，一张图像的平均亮度是像素最大值的四分之一时我们认为它是亮度合适的（注意这条法则不适用于所有场景，例如一张夜景图像中平均亮度往往会很小）。因此我们调整全局亮度使其符合这一假设。<br>接下来主要介绍 Gamma 校正。Gamma 曲线是图像、信号处理领域使用最为广泛的非线性处理，我们最容易见到的就是 Photoshop 中的“曲线”功能，它就相当于对图像做了一次 Gamma 校正。Gamma 校正是一个很大的话题，这里不具体介绍。由于使用的 Gamma 曲线是一条凸函数，相当于把图像暗部的细节展宽，因此得到的图像要比校正前更亮。<br>算法是通过将 S 形反色增强色调曲线与标准 sRGB 色彩分量转换功能连接起来，以增加对比度并应用 sRGB 伽玛校正。<br>4.10 色差校正<br>色差又称为“色散现象”，是由于照相机的镜头没有把不同波长的光线聚焦到同一个焦平面，或者和镜头对不同波长的光线放大的程度不同而形成的。色差又可分为“纵向色差”和“横向色差”，色差的程度随着镜头表面玻璃的色散程度不同而有所差异。相机镜头是用白光来形成影像的，而白光则是由各种不同波长的可见光组合而成。虽然同是电磁波，不过不同波长(颜色)的可见光在穿过玻璃时会有不同的速度，因此亦有所谓不同的折射率。利用这个原理，只要利用菱镜便可将白光分解成不同颜色(波长)的光线。<br>相机镜头由玻璃构成，利用折射原理将可见光聚焦而成为影像。光线穿过镜头后，有机会出现类似菱镜的效果，不同波长的光线不能在同一焦点上聚焦，在影像上形成色散，即是所谓的紫边现像。理论上色散在影像中央及边缘都可以发生，不过由于边缘的光程较长，因此色散也就特别明显。由于短波长的折射率较高，因此紫色对色差也特别敏感。由色差而形成的紫边，通常可以在画面边缘看到，而由于紫色折射得较多，所以紫边一般都是由内向外扩散。此外，远摄镜头的光程长，色散的现像也就特别容易看到。<br>可隐藏横向和纵向色差。不假设镜头模型，而是沿着高对比度边缘查找像素，并从不太可能受色差影响的附近像素中替换色度。<br>4.11 使用反锐化掩模进行锐化<br>将原图像通过反锐化掩模进行模糊预处理)后与原图逐点做差值运算，然后乘上一个修正因子再与原图求和，以达到提高图像中高频成分、增强图像轮廓的目的.反锐化掩模技术最早是应用于摄影技术中，以增强图像的边缘和细节。光学上的操作方法是将聚焦的正片和散焦的负片在底片上进行叠加，结果是增强了正片高频成份，从而增强了轮廓，散焦的负片相当于“模糊”模板（掩模），它与锐化的作用正好相反，因此，该方法被称为反锐化掩模法。<br>这里使用由 3 级卷积金字塔构建的高斯核的总和来实现[24]。<br>4.12 色调特定<br>通过将蓝色的青色和紫色转换为淡蓝色来实现，并且通常会增加蓝色和绿色的饱和度。<br>4.13 抖动<br>多年来，数码相机中的图像噪点问题一直是摄影师所关注的。图像噪点常常被描述为卤化银胶片颗粒的等价物。尽管噪点看上去与照片和幻灯片中的颗粒差不多，但是当它以低频杂色或与伪色相结合出现时，可能更加令人厌烦。众所周知，数码相机的噪点主要是指数字影像传感器将光线作为接收信号并输出的过程中所产生的图像中的粗糙部分，也指图像中不该出现的外来像素，通常由电子干扰产生。至于它产生的源头难以去界定，可以肯定的是产生噪点的源头不止一个，而且在图像强度中都是以变化的形式出现的。<br>它形成的根源主要是因为不均匀暗电流，整个传感器阵列中每个像素上的暗电流都不一致的时候，就产生了噪点。暗电流是一股微电流，它持续不断地流遍整个设备，即便没有光子到达传感器也是如此。由于暗电流产生是一个随机的过程，所以减少DCNU 引起的噪点是有可能的，通过从被摄图像上减去每个像素的平均暗电流可以减少噪点，但无法消除它。<br>多数 FPN 噪点是在黑暗条件下产生的。常照明条件下，不均匀暗电流（DCNU）一般是看不见的，但是如果曝光时间较长时，就能够观察到。长时间曝光，使传感器产生高温，而高温能够加重不均匀暗电流 DCNU，所以在长时间曝光、曝光不足或光线条件较差的情况下，所摄图像噪点较为明显。而天文摄影中，使用的传感器要经过不断冷却以降低 DCNU 的程度，以此来降低噪点。<br>大部分数码相机都会采用某种内部处理的方式降低图像的噪点水平。在将图像传输到电脑之后，使用具有降噪功能呢的软件进行处理，也能减少图像中的噪点。程度严重的噪点较难清除，尤其当噪点和色彩伪像混合时最难以清除。这种情况下，降噪算法有时不能降噪和精微的图像细节区分开来。有时宁可在图像上留下噪点也不能一味的大规模应用降噪功能，因为这会导致图像细节的损失。<br>我们使用的算法是当从每像素 12 位减少到 8 位显示时，抖动以避免量化伪像，通过从预先计算的表中添加蓝噪点来实现。<br>总的来说，动态范围压缩对于高动态范围场景，使用本地色调映射来减少高光和阴影之间的对比度，同时保留局部对比度。这里选择的色调映射方法是暴露融合的变体[25]。给定以不同亮度级别描绘相同场景的输入图像时，曝光融合使用图像金字塔来混合输入图像的最佳曝光部分，以生成单一输出图像，看起来很自然并且具有比输入更少的曝光不足区域。<br>通常将曝光融合应用于使用包围拍摄的图像。在该流水线中，采用恒定曝光捕捉多个帧，而不是包围。为了使曝光融合适应流水线，通过对其进行增益和伽玛校正，从中间 HDR 图像中获得“合成曝光”，然后将它们融合，就好像它们已经通过包围拍摄一样。这里选择以灰度进行这些提取，并且只创建两个合成曝光 - 一个短和一个长。短时间曝光告诉我们有多少像素会被吹出，并成为捕捉过程中使用的整体曝光，而短曝光和长曝光之间的比例告诉我们正在应用多少动态范围压缩。这两个值都来自自动曝光算法。<br>融合灰度而不是彩色图像，只使用两种合成曝光，可以减少计算和内存要求。与Mertens 等人的工作相比，它还使像素混合权重得以简化[25]。特别是，使用亮度固定的加权函数，有利于中等亮度的像素。该函数可以表示为一维查找表。 融合合成曝光后，撤销所得灰度图像的伽玛校正，并通过复制原始线性 RGB 图像中的像素色度比例来对其进行重新着色[13]。<br>5 滤镜算法实现与分析<br>5.1 实验环境配置<br>系统：Ubuntu 14.04<br>编译器：LLVM 编译器<br>语言：Halide 语言(嵌于 C++)<br>首先，LLVM 的命名最早来源于底层语言虚拟机（Low Level Virtual Machine）的缩写。它是一个用于建立编译器的基础框架，以 C++编写。创建此工程的目的是对于任意的编程语言，利用该基础框架，构建一个包括编译时、链接时、执行时等的语言执行器。而我们要进行代码实现的Halide语言则构建在 LLVM Clang 编译的基础之上，而代码实现之所以选择使用 Halide 语言，则是由于 Halide 能够自动优化代码（对常规的编程语言，这个过程需要花费数小时来手工完成），因此，Halide 语言编写的程序的运行速度也会显著提高。MIT 的研究测试人员曾用 Halide 重写了几个常用的图像处理算法（这些算法都事先经过熟练的程序员优化）。Halide 版本编写的算法在代码量上比传统算法大体要多出 1/3，但性能却有极大的提升，加速比能够加速达 2 倍、3 倍甚至6 倍。在其中一个算法中，Halide 程序虽然比原程序长，但却取得是了 70 倍的加速比。<br>5.2 代码实现<br>整个代码实现分成 5 个模块，首先要将图片载入程序，与传统图片处理不同。因为本滤镜算法要求的输入图片为保存了更多图片信息的 Raw 文件，而非传统的 JPEG文件。为了识别相应的 Raw 文件，先使用 dcraw 工具将 Raw 文件转换为 PGM 点阵图格式文件，保证导出的图像为 16 位（而不是常见的 JPEG 的 8 位 ）、且不进行任何白平衡校正和任何伽马校正。同时还可以利用 dcraw 将输入图像解析为 tiff 格式，获取拜耳图片的四颜色通道的阴影系数信息，方便后续进行去马赛克工作。并对图像尺寸和格式进行核对确认。<br>完成载入图像后，为了在后续进行图像对齐操作时，加快代码运行速度，这里利用 Halide 语言将图像在 x 轴和 y轴上的偏移量以结构体的形式单独定义。并利用 Halide语言将这个结构体定义成数字常量形式，并对该结构体的所有运算形式进行重载，从而实现简化代码结构并且提高运算速度。<br>然后再将图像采样，高斯内核模糊边界以及伽玛校正部分利用 halide 语言进行重写方便后续的对齐操作。图像对齐时，按照前述算法将每个非参考帧与参考帧进行对齐，并记录相对于参考图像最接近匹配图块的在 x 轴和 y 轴上偏移量。然后进行图像合并，将对齐的帧在时间和空间维度上进行合并去噪。因为输入的是原始图片，未做任何处理，所以要追加白平衡设置、伽马校正、色彩空间转换、去马赛克、亮度调节等功能。最后将 16 位图片转置并输出为标准 8 位图片即可。<br>5.3 实验分析<br>使用 HDR+滤镜产生的图像比标准管道的图像更亮。另外，通过减少空间去噪，我们可以保留低对比度的细节。在减少运动模糊方面，HDR+滤镜算法使用的时间比传统流水线所用时间更短。并帮助我们在参考帧的选择中找到的最清晰的帧。图 5.1、图 5.2、图 5.3 和图 5.4 显示了使用 HDR+滤镜处理图像的示例照片。使用HDR+滤镜处理图像总能产生优于传统单一曝光管线的效果，并且在动态范围较大或低光的场景中，改善效果通常很明——较少的高光溢出或压碎的阴影，较少的噪点，较少的运动模糊，较好的色彩，更清晰的细节和更多的纹理。<br>为了更详细地评估我们的系统的对齐和合并方法，证明其与现有技术的爆裂融合相比的稳健性，参见论文[7,26-27]。<br>5.3.1 性能分析<br>为了使使用 HDR+滤镜算法管道足够快的运行，我们选择了优化算法来提高计算效率。这意味着避免非本地通信和数据依赖性，这些依赖性排除了并行化，尽可能少地使用存储器，并且尽可能地采用定点算术。这些同样的担忧妨碍了使用具有全局迭代的算法（例如，FlexISP[27]），大的或动态的空间支持（例如，BM3D[18]）或昂贵的色调映射（例如局部拉普拉斯滤波器[28]）。本算法的大部分代码都是 Halide 编写的[29]。另外，由于算法中计算了许多用于对齐和合并的小 2D 实数 DFT，所以为了加快运行速度，算法在 Halide 中实现了自己的 FFT。对于算法管道中的小型 DFT，这种实现比基于 ARM 的移动电话上的 FFTW 快五倍[30]。<br>5.3.2 问题与展望<br>参数设置问题。非常遗憾的是在判断图像长宽，黑白电平时只能定义为不可改变量，导致后续部署服务器时，只能处理符合以上条件的图片，从而使得该算法在这方面非常弱势。<br>输入图片的拜耳格式限制为 RGGB 格式。处理办法是判断格式，如果为 BGGR格式，则交换红蓝通道存虽然图像质量一般都很好，但使用 HDR+滤镜处理图像还是出现了一些极端情况，图 5.5、图 5.6 和图 5.7 显示了其中一些情况，大概占总数的 5%左右。<br>此外，如果场景的动态范围太高以至于使用两次合成曝光进行曝光融合将会使图片产生卡通效果，那么我们将场景视为其动态范围较低并且允许更多像素点被吹出。使用三种合成曝光效果可能会更好，但计算起来很昂贵，需要对自动曝光数据库进行更细微的调整。此外，如果一个场景在如此短的曝光时间下仍然有模糊的快速运动，则对齐可能会失败，从而在输出照片上留下过多的噪点。<br>我们最严重的失败模式是，在非常低的光照水平下，ISP 的自动对焦和白平衡估计开始失败。尽管合并和对齐可能仍然有效，但照片可能会失焦或产生偏色。图 5.5、图 5.6 和图 5.7 中可以看到轻微的模型。<br>(a)算法处理后<br>(b)原图<br>图 5.1 强光背景下 HDR+滤镜处理出来的结果</p>
<p>(a)算法处理后</p>
<p>(b)原图<br>图 5.2 暗光背景下 HDR+滤镜处理出来的结果</p>
<p>(a)算法处理后</p>
<p>(b)原图<br>图 5.3 闪光灯场景下 HDR+滤镜处理出来的结果</p>
<p>(a)算法处理后</p>
<p>(b)原图<br>图 5.4 傍晚场景下 HDR+滤镜处理出来的结果</p>
<p>(a)算法处理后<br>(b)原图<br>图 5.5 一些处理不好的图片情况（1）</p>
<p>(a)算法处理后<br>(b)原图<br>图 5.6 一些处理不好的图片情况（2）</p>
<p>(a)算法处理后</p>
<p>(b)原图<br>图 5.7 一些处理不好的图片情况（3）</p>
<p>6 结论<br>本论文主要描述的是高动态范围增强摄影滤镜算法，该算法执行的主要流程过程包括对齐、合并和精加工三个主要部分。相比传统的图像增加算法，该算法的优势在于输入的原始图像为拜耳原始图像，该图像具有较高的比特深度，其图像的比特位宽要比传统图像高出两位，这使得图像的细节更加丰富，可以获得更加完整的原始图像。相比传统成像生成的传统图像，该滤镜算法生成的图像有更高的更好的质量。因为该算法已经通过 pixel2 手机在市场上流通半年之久，其用户反馈包括各大平台测评的结果甚至超过大多数双摄手机的成像效果。<br>同时，为了测试该滤镜算法的效果，我从 Google Cloud SDK 上下载了 153 个样例进行测试，通过样例测试的结果来观察该算法在图像处理上的优劣。每一个样例都包含一个连拍图像文件夹，其中的具体内容包括输入的原始弱格式的 dng 图片，这种图片是输入设备上捕获的连拍照片。对于包含光学屏蔽像素的设备，图像已被裁剪为有效像素阵列。对于数码变焦拍摄的少数照片，原始输入已预先裁剪到摄影师选择的视野。此外，还有低分辨率浮点增益图 tiff 格式文件，该图列出了用于校正每个拜耳颜色通道的颜色阴影和晕影输入的系数。存储为 4 通道浮点 TIFF 图像。通道顺序是[R，Gred，Gblue，B]，其中 Gred 是拜耳模式中含红色行的绿色通道，Gblue 是是拜耳模式中含蓝色行的绿色通道。两个 txt 文件分别为色彩转换矩阵系数文件和时间花费文件，色彩转换矩阵系数文件用于从传感器 RGB 色彩空间转换为输出线性 sRGB 色彩空间的 3x3 色彩转换矩阵的系数，按行优先顺序排列[31,32]。请注意，应用于拜耳原始颜色通道的白平衡增益未包括在矩阵中; 这些可以被确定为 DNG 标签中系数的倒数。时间花费文件中描述了对齐，合并和精加工阶段的设备时序。这些时间安排是为了完整性，但并不反映我们系统的当前性能。此外，Google 给出的最终输出图片是 final.jpg，但实际算法应用时只能生成 PNG 格式的图片。<br>该算法目前仍存在很多缺陷，比如该算法处理的图像必须是原始的，未被处理的图像，因为这种未处理的图像记录了更多场景信息，保留了更宽广的色域以及动态范围，这样可输入图像的格式就被限定在一些弱格式的输入图像中。这样可输入图像的格式就被限定在一些弱格式的输入图像中，例如常见的<em>.CR2、</em>.NEF、 <em>.ARW、  </em> .ORF、<em> </em>.RAF、**.DNG 等。而手机拍摄后直接生成的 JPG 图像，这种已经通过 ISP 处理封装并压缩后的图片则会因为无法解析而无法作为输入图片。但也正是因为这些图片经过处理已经丢失了很多图片信息而难以进行效果明显的优化。<br>此外，HDR+滤镜算法的运行时间仍然过长，目前测试时长大概在两分钟左右，时间成本仍然不低，而且在一些极端情况下仍会出现颜色过红的情况，以及为了追求过度的降低噪点，而不得不牺牲图像清晰度的情况。</p>
<p>参考文献<br>[1] Telleen J, Sullivan A, Yee J, et al. Synthetic Shutter Speed Imaging[C]. Computer Graphics Forum.Blackwell Publishing Ltd, 2007:591–598..<br>[2] Berthold K.P. Horn, Brian G. Schunck. Determining optical flow[J]. Artificial Intelligence, 1981,17(1–3):185-203.<br>[3] Wilburn B, Joshi N, Vaish V, et al. High performance imaging using large camera arrays[J]. AcmTransactions on Graphics, 2005, 24(3):765-776.<br>[4] Petschnigg G, Szeliski R, Agrawala M, et al. Digital photography with flash and no-flash imagepairs[C]. Acm Siggraph. ACM, 2004:664-672.<br>[5] Reinhard E, Ward G, Pattanaik S, et al. High dynamic range imaging : acquisition, display, andimage-based lighting[M]. Political parties and the state :. Princeton University Press, 2005:2039 -2042.<br>[6] Lucas B D, Kanade T. An iterative image registration technique with an application to stereovision[C]. International Joint Conference on Artificial Intelligence. Morgan Kaufmann PublishersInc. 1981:674-679.<br>[7] Liu Z, Yuan L, Tang X, et al. Fast burst images denoising[J]. Acm Transactions on Graphics, 2014,33(6):1-9.<br>[8] Thomas Brox, Jitendra Malik. Large Displacement Optical Flow: Descriptor Matching inVariational Motion Estimation[J]. IEEE Trans Pattern Anal Mach Intell, 2011, 33(3):500-513.<br>[9] Yamaguchi K, Mcallester D, Urtasun R. Efficient Joint Segmentation, Occlusion Labeling, Stereoand Flow Estimation[C]. European Conference on Computer Vision. Springer, Cham,2014:756-771.<br>[10] Wiegand, Thomas, Sullivan, Gary J, Bjøntegaard, Gisle, et al. Overview of the H.264/AVC videocoding standard[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2003,13(7):560-576.<br>[11] Lewis J P. Fast Normalized Cross-Correlation[J]. Circuits Systems &amp; Signal Processing, 1995,82(2):144–156.<br>[12] Joshi N, Cohen M F. Seeing Mt. Rainier: Lucky imaging for multi-image denoising, sharpening,and haze removal[C]. IEEE International Conference on Computational Photography. IEEE,2010:1-8.<br>[13] Levoy M, et al. Burst photography for high dynamic range and low-light imaging on mobilecameras[J]. Acm Transactions on Graphics, 2016, 35(6):192.<br>[14] Tao, Michael, Bai, Jiamin, Kohli, Pushmeet, et al. SimpleFlow: A Non-iterative, Sublinear OpticalFlow Algorithm[J]. Computer Graphics Forum, 2012, 31(2pt1):345-353.<br>[15] Stone H S, Orchard M T, Chang E C, et al. A fast direct Fourier-based algorithm for subpixelregistration of images[J]. Geoscience &amp; Remote Sensing IEEE Transactions on, 2001,39(10):2235-2243.<br>[16] Farneback G. Polynomial Expansion for Orientation and Motion Estimation[J]. LinköpingUniversity Sweden, 2009.<br>[17] Kokaram D A C. Motion Picture Restoration[M]. Springer London, 1998.<br>[18] Dabov K, Foi A, Egiazarian K. Video denoising by sparse 3D transform-domain collaborativefiltering[C]. Signal Processing Conference, 2007, European. IEEE, 2015:145-149.<br>[19] Delbracio M, Sapiro G. Hand-Held Video Deblurring Via Efficient Fourier Aggregation[J]. IEEETransactions on Computational Imaging, 2015, 1(4):270-283.<br>[20] Healey G, Kondepudy R. Radiometric CCD camera calibration and noise estimation[J]. IEEETransactions on Pattern Analysis &amp; Machine Intelligence, 2002, 16(3):267-276.<br>[21] Makitalo. Optimal inversion of the generalized Anscombe transformation for Poisson-Gaussiannoise.[J]. IEEE Transactions on Image Processing A Publication of the IEEE Signal ProcessingSociety, 2013, 22(1):91-103.<br>[22] Donoho D L. De-noising by soft-thresholding[J]. IEEE Transactions on Information Theory, 2002,41(3):613-627.<br>[23] S. Farsiu, M. Elad, P. Milanfar. Multiframe demosaicing and super-resolution of color images[J].IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society, 2005,15(1):141-159.<br>[24] Farbman Z, Fattal R, Lischinski D. Convolution pyramids[C]. SIGGRAPH Asia Conference. ACM,2011:175.<br>[25] Mertens T, Kautz J, Reeth F V. Exposure Fusion[C]. Conference on Computer Graphics &amp;Applications. IEEE Computer Society, 2007:382-390.<br>[26] ADOBE INC., Photoshop CC [EB/OL], <a href="http://www.adobe.com/creativecloud.html" target="_blank" rel="noopener">http://www.adobe.com/creativecloud.html</a>. 2015.1.2.2016.<br>[27] Felix Heide, Orazio Gallo, Orazio Gallo, et al. FlexISP: a flexible camera image processingframework[J]. Acm Transactions on Graphics, 2014, 33(6):231.<br>[28] Mathieu Aubry, Sylvain Paris, Samuel W. Hasinoff, et al. Fast Local Laplacian Filters:Theory andApplications[J]. ACM Transactions on Graphics (TOG), 2014, 33(5):1-14.<br>[29] Ragan J. Decoupling Algorithms from Schedules for Easy Optimization of Image ProcessingPipelines[J]. Acm Transactions on Graphics, 2012, 31(4):13-15.<br>[30] Frigo M, Johnson S G. The Design and Implementation of FFTW3[J]. Proceedings of the IEEE,2005, 93(2):216-231.<br>[31] 丁丽媛. 基于稀疏表示的 Bayer 彩色滤波阵列插值算法研究[D]. 燕山大学, 2011.<br>[32] 刘方. 基于 Bayer 彩色滤波阵列插值算法的研究[D]. 电子科技大学, 2006.</p>
<p><center>致 谢</center><br>经历将近三个月坚持院楼打卡的时间，终于写完了这篇论文。在这段充满艰辛和奋斗的历程中，我感受到了完成学术任务的艰辛和困苦，深深体会到自身能力的不足。在整个写作过程和项目完成中，我遇到了无数的困难和障碍，非常幸运在同学和老师的帮助下度过了大部分困难经历。在这里我尤其要强烈感谢我的论文指导老师—陈浩老师，没有他对我的不厌其烦的指导和帮助，就没有我这篇论文的最终完成。同时再次感谢我的父母在我这段孤独奋战过程中给予的支持和鼓励。在此，我向指导和帮助过我的老师们，同学们，家长表示最衷心的感谢！<br>同时，我也要感谢本论文所引用的各位学者的专著，如果没有这些学者的研究成果的启发和帮助，我将无法完成本篇论文的最终写作。至此，我也要感谢我的朋友和同学，他们在我写论文的过程中给予我了很多有用的素材，也在论文的排版和撰写过程中提供热情的帮助！由于我的学术水平有限，所写论文难免有不足之处，恳请各位老师和同学批评和指正！</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/HDR/" rel="tag"># HDR+</a>
          
            <a href="/tags/图像/" rel="tag"># 图像</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/12/hello-world/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/13/JAVA-Socket的聊天室项目/" rel="prev" title="JAVA Socket的聊天室项目 ">
                JAVA Socket的聊天室项目  <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/background.jpg" alt="baige jiang">
            
              <p class="site-author-name" itemprop="name">baige jiang</p>
              <p class="site-description motion-element" itemprop="description">Record learning notes at any time</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/jiangbaige" title="GitHub &rarr; https://github.com/jiangbaige" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:719188428@qq.com" title="E-Mail &rarr; mailto:719188428@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">baige jiang</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.0.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.0"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>



  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
